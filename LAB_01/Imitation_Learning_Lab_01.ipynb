{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imitation_Learning_Lab_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMawyLEW_AGn"
      },
      "source": [
        "# Imitation Learning - Lab 01\n",
        "\n",
        "O objetivo desta laboratório é experimentar a aprendizagem por imitação (imitation learning), em que o modelo (rede) aprende a imitar as ações de um especialista (humano). No lugar de experiências coletadas de um especialista humano, aqui as demonstrações serão fornecidas por meio de uma política de especialistas que treinamos para você. \n",
        "\n",
        "- Usaremos um tipo de aprendizado por imitação, conhecido como clonagem comportamental (behavioral cloning). Isso significa que treinaremos nossa rede de forma supervisionada.\n",
        "- A saída da rede é a política de direção, representada pelo ângulo de direção desejado e/ou aceleração ou frenagem. Por exemplo, podemos ter um neurônio de saída de regressão para o ângulo de direção e um neurônio para aceleração ou frenagem (já que não podemos ter os dois ao mesmo tempo).\n",
        "- A entrada da rede pode ser:\n",
        "Dados brutos do sensor. Por exemplo, uma imagem da câmera. \n",
        "- Criaremos o conjunto de dados de treinamento com a ajuda do especialista. Em cada etapa da jornada, iremos registrar:\n",
        "    - O estado atual do ambiente. Estes podem ser os dados brutos do sensor ou a representação da vista de cima para baixo. Usaremos o estado atual como entrada para o modelo.\n",
        "    - As ações do especialista no estado atual do ambiente (ângulo de direção, freio / aceleração). Esses serão os dados de destino da rede. Durante o treinamento, vamos minimizar o erro entre as previsões da rede e as ações usando gradient descent. Desta forma, ensinaremos a rede a imitar o especialista.\n",
        "\n",
        "<br>\n",
        "\n",
        "A seguir está uma ilustração do cenário de Behavioral Cloning:\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1ozI1x1hNgIa_IXNsxUm4V-YFADXlKxus' width=\"600\" height=\"400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdeHy9MGAbO_"
      },
      "source": [
        "## (Início) Configuração\n",
        "\n",
        "Você precisará fazer uma cópia deste notebook em seu Google Drive antes de editar. Você pode fazer isso com **Arquivo → Salvar uma cópia no Drive**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUVKyTmt1caC"
      },
      "source": [
        "# !pip install google-colab > /dev/null 2>&1\n",
        "# !python --version"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVXv60zj3LIJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-CfOCXFoxd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147969cc-60d9-4dda-b68e-1b8f7b7189e1"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QKwdXhlAyiw"
      },
      "source": [
        "# Seu trabalho será armazenado em uma pasta chamada `minicurso_rl` por padrão \n",
        "# para evitar que o tempo limite da instância do Colab exclua suas edições\n",
        "\n",
        "\n",
        "DRIVE_PATH = \"/content/gdrive/My\\ Drive/minicurso_rl\"\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace(\"\\\\\", \"\")\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "SYM_PATH = \"/content/minicurso_rl\"\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eDEgSARy30b"
      },
      "source": [
        "Instalando as dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2V0MD29BoEr"
      },
      "source": [
        "!pip install -U cloudpickle > /dev/null 2>&1 \n",
        "!pip install \"gym[all]\" > /dev/null 2>&1 \n",
        "!pip install \"gym[box2d]\" > /dev/null 2>&1 \n",
        "!pip install \"stable-baselines3[extra]\" > /dev/null 2>&1 \n",
        "\n",
        "!apt-get install x11-utils > /dev/null 2>&1 \n",
        "!pip install pyglet > /dev/null 2>&1 \n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "\n",
        "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "\n",
        "!pip install plotly > /dev/null 2>&1\n",
        "\n",
        "!pip install pyarrow > /dev/null 2>&1\n",
        "!pip install -U scikit-learn > /dev/null 2>&1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnns06ycVXRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b168fc1-c464-4237-d443-0d6e6bcadd32"
      },
      "source": [
        "! wget http://www.atarimania.com/roms/Roms.rar\n",
        "! mkdir /content/ROM/\n",
        "! unrar e /content/Roms.rar /content/ROM/\n",
        "! python -m atari_py.import_roms /content/ROM/ > /dev/null 2>&1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-16 15:29:11--  http://www.atarimania.com/roms/Roms.rar\n",
            "Resolving www.atarimania.com (www.atarimania.com)... 195.154.81.199\n",
            "Connecting to www.atarimania.com (www.atarimania.com)|195.154.81.199|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11128004 (11M) [application/x-rar-compressed]\n",
            "Saving to: ‘Roms.rar.2’\n",
            "\n",
            "Roms.rar.2          100%[===================>]  10.61M   636KB/s    in 18s     \n",
            "\n",
            "2021-10-16 15:29:29 (618 KB/s) - ‘Roms.rar.2’ saved [11128004/11128004]\n",
            "\n",
            "mkdir: cannot create directory ‘/content/ROM/’: File exists\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/Roms.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file /content/ROM/HC ROMS.zip\n",
            "11826711 bytes, modified on 2019-12-22 11:24\n",
            "with a new one\n",
            "11826711 bytes, modified on 2019-12-22 11:24\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit E\n",
            "\n",
            "No files to extract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgehcZJTarmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110080f1-4ec7-4e7d-b7ac-8c2376d07fb9"
      },
      "source": [
        "!cd minicurso_rl && gdown --id 1ZV5fvCbU_gbTy1AraSR-ymNsiNQesBvt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZV5fvCbU_gbTy1AraSR-ymNsiNQesBvt\n",
            "To: /content/gdrive/My Drive/minicurso_rl/EnduroNoFrameskip-v4.zip\n",
            "\r  0% 0.00/20.8M [00:00<?, ?B/s]\r 48% 9.96M/20.8M [00:00<00:00, 99.4MB/s]\r100% 20.8M/20.8M [00:00<00:00, 97.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3mf1jw3aww"
      },
      "source": [
        "## (Sempre) Importações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GYJ_PX56rSR"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# torch.multiprocessing.set_start_method('spawn')\n",
        "torch.manual_seed(10)\n",
        "random.seed(10)\n",
        "np.random.seed(10)\n",
        "eval_episodes = 10"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K8iccKbF754"
      },
      "source": [
        "## (Sempre) Ambiente\n",
        "\n",
        "O ambiente utilizado será o Enduro-v0, um ambiente [OpenAI Gym](https://gym.openai.com/envs/Enduro-v0/) de corrida.\n",
        "\n",
        "[Gym](https://gym.openai.com/docs/) é um kit de ferramentas para desenvolver e comparar algoritmos de aprendizagem por reforço. Ele não faz suposições sobre a estrutura do seu agente e é compatível com qualquer biblioteca de computação numérica.\n",
        "\n",
        "O estado do ambiente Enduro consiste em 210x160 pixels.Uma recompensa de +1 é dada para cada carro ultrapassado e -1 para cada carro que passa pelo agente (mas a recompensa mínima é 0).\n",
        "\n",
        "O objetivo consiste em manobrar um carro de corrida no National Enduro, uma corrida de resistência de longa distância. O objetivo da corrida é passar um certo número de carros a cada dia. Isso permitirá que o jogador continue correndo no dia seguinte. O piloto deve evitar outros pilotos e ultrapassar 200 carros no primeiro dia e 300 carros em cada dia seguinte.\n",
        "\n",
        "Conforme o tempo passa, a visibilidade também muda. Quando é noite no jogo, o jogador só pode ver as luzes traseiras dos carros que se aproximam. Com o passar dos dias, os carros também se tornarão mais difíceis de evitar. O clima e a hora do dia são fatores importantes para jogar. Durante o dia, o jogador pode dirigir por um trecho de gelo na estrada que limitaria o controle do veículo, ou um trecho de neblina pode reduzir a visibilidade.\n",
        "\n",
        "[Descrição da Wikipedia](https://en.wikipedia.org/wiki/Enduro_%28video_game%29)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e2x7FjtERCk"
      },
      "source": [
        "# Procedimento para renderizar o ambiente no Google Colab\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt, animation\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "\n",
        "def create_anim(frames, dpi, fps):\n",
        "    plt.figure(figsize=(frames[0].shape[1] / dpi, frames[0].shape[0] / dpi), dpi=dpi)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    def setup():\n",
        "        plt.axis('off')\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, init_func=setup, frames=len(frames), interval=fps)\n",
        "    return anim\n",
        "\n",
        "def display_anim(frames, dpi=72, fps=60):\n",
        "    anim = create_anim(frames, dpi, fps)\n",
        "    return anim.to_jshtml()\n",
        "\n",
        "def save_anim(frames, filename, dpi=72, fps=50):\n",
        "    anim = create_anim(frames, dpi, fps)\n",
        "    anim.save(filename)\n",
        "\n",
        "\n",
        "class trigger:\n",
        "    def __init__(self):\n",
        "        self._trigger = True\n",
        "\n",
        "    def __call__(self, e):\n",
        "        return self._trigger\n",
        "\n",
        "    def set(self, t):\n",
        "        self._trigger = t"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7pkNyBjzMy1"
      },
      "source": [
        "import gym\n",
        "environment_id = \"EnduroNoFrameskip-v4\"       # Nome do ambiente utilizado"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7foeM827r6I"
      },
      "source": [
        "## Visualizar\n",
        "\n",
        "Interagimos no ambiente através da função `step`, que nos retorna quatro valores: observação, recompensa, done, info. Esta é uma implementação do clássico “loop agente-ambiente”. A cada passo de tempo, o agente escolhe uma ação e o ambiente retorna uma observação e a recompensa.\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1TXdjYkbfm2EvtCbVIpe5BkUgXJY1d1zE' width=\"600\" height=\"250\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--EwWyyKEN4P",
        "outputId": "cd7235ce-3b10-4b7e-821f-7245fa62d8b3"
      },
      "source": [
        "env = gym.make(environment_id)                # Criando o ambiente\n",
        "\n",
        "frames = []\n",
        "episodes = 1\n",
        "for episode in range(1, episodes+1):\n",
        "    obs = env.reset()     # Retorna a observação inicial\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        frames.append(env.render(mode='rgb_array'))     # Renderizando o ambiente\n",
        "        action = env.action_space.sample()              # Seleciona uma ação aleatória\n",
        "        n_obs, reward, done, info = env.step(action)    # Executa a ação selecionada\n",
        "        score += reward\n",
        "        obs = n_obs.copy()\n",
        "    print(\"\\n\\nEpisódio: {} Pontuação: {}\".format(episode,score))\n",
        "env.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Episódio: 1 Pontuação: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JvCqsFCEadc"
      },
      "source": [
        "display.HTML(display_anim(frames))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jQFnEqE7je3"
      },
      "source": [
        "## (Sempre) Carregar Modelo Especialista\n",
        "\n",
        "O modelo especialista que estamos disponibilizando para você é um agente de aprendizado por reforço treinado com o algoritmo Proximal Policy Optmization (PPO). Para isso, foi utilizado a biblioteca [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/), que contém uma série de implementações de algoritmos de Aprendizado por Reforço em PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH6R9BG2bY3n"
      },
      "source": [
        "from stable_baselines3 import PPO, A2C\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4UFIcHJ7is5"
      },
      "source": [
        "expert = PPO.load(\"minicurso_rl/EnduroNoFrameskip-v4\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0550zylM3Jd"
      },
      "source": [
        "## (Sempre) Processar ambiente\n",
        "\n",
        "Para criar o ambiente iremos aplicar alguns processamentos que irão ajudar o agente.\n",
        "\n",
        "Os wrappers nos permitirão adicionar funcionalidade aos ambientes, como modificar observações e recompensas a serem fornecidas ao nosso agente. É comum na aprendizagem por reforço pré-processar as observações para torná-las mais fáceis de aprender. Um exemplo comum é ao usar entradas baseadas em imagem, para garantir que todos os valores estejam entre 0 e 1 ao invés de entre 0 e 255, como é mais comum com imagens RGB.\n",
        "\n",
        "Para mais detalhes dos wrappers utilizados veja em: [Atari Wrappers](https://stable-baselines3.readthedocs.io/en/master/common/atari_wrappers.html) e [Vectorized Environments](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html?highlight=make_vec_env#multiprocessing-unleashing-the-power-of-vectorized-environments)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te8GATTMgzyJ"
      },
      "source": [
        "env = make_vec_env(environment_id, wrapper_class=AtariWrapper)\n",
        "env = VecFrameStack(env, 4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVOfCTfrrWZd"
      },
      "source": [
        "## (Demora) Vamos ver o quão bem o especialista consegue se sair no ambiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tdWi45r1e4U",
        "outputId": "5954f146-47a7-4955-afc6-a3d5fdba490f"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(expert, env, n_eval_episodes=eval_episodes)\n",
        "print(f\"Recompensa média = {mean_reward} +/- {std_reward}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa média = 1317.5 +/- 349.2409626604531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMR4o-MxfhOM"
      },
      "source": [
        "frames = []\n",
        "episodes = 1\n",
        "for episode in range(1, episodes+1):\n",
        "    obs = env.reset()     # Retorna a observação inicial\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        frames.append(env.render(mode='rgb_array'))       # Renderizando o ambiente\n",
        "        action = expert.predict(obs, deterministic=True)  # Seleciona uma ação do agente especialista\n",
        "        n_obs, reward, done, info = env.step(action)      # Executa a ação selecionada\n",
        "        score += reward\n",
        "        obs = n_obs.copy()\n",
        "    print(\"\\n\\nEpisódio: {} Pontuação: {}\".format(episode,score))\n",
        "env.close()\n",
        "\n",
        "display.HTML(display_anim(frames))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93-BHhi5CKI6"
      },
      "source": [
        "## Armazenar informações do especialista\n",
        "\n",
        "Agora, deixamos nosso especialista interagir com o ambiente e armazenar as observações e ações de especialistas resultantes para construir um conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2tziC8Yr2Rd"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXjvoWS9CANk"
      },
      "source": [
        "num_interactions = int(3e4)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSZCmJ6yCM2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2615e46e-890a-4424-ac9e-af8e9d4ad6db"
      },
      "source": [
        "if isinstance(env.action_space, gym.spaces.Box):\n",
        "    expert_observations = np.empty((num_interactions,) + env.observation_space.shape)\n",
        "    expert_actions = np.empty((num_interactions,) + (env.action_space.shape[0],))\n",
        "else:\n",
        "    expert_observations = np.empty((num_interactions,) + env.observation_space.shape)\n",
        "    expert_actions = np.empty((num_interactions,) + env.action_space.shape)\n",
        "\n",
        "# HW: Interaja  com o ambiente `env` conforme visto anteriormente. Armazene \n",
        "# as observações e as ações do especialista em `expert_observations` e \n",
        "# `expert_actions` respectivamente para construir o dataset.\n",
        "obs = env.reset()     # Retorna a observação inicial\n",
        "done = False\n",
        "score = 0\n",
        "count = 0\n",
        "\n",
        "while not done and count < num_interactions:\n",
        "    expert_observations[count] = obs.copy()\n",
        "    action = expert.predict(obs, deterministic=True)  # Seleciona uma ação do agente especialista\n",
        "    expert_actions[count] = action[0]\n",
        "    n_obs, reward, done, info = env.step(action)      # Executa a ação selecionada\n",
        "    score += reward\n",
        "    obs = n_obs.copy()\n",
        "    count += 1\n",
        "print(\"\\n\\nPontuação: {}\".format(score))\n",
        "env.close()\n",
        "\n",
        "# Salva os dados (observação, ação)\n",
        "np.savez_compressed(\n",
        "    \"minicurso_rl/expert_data\",\n",
        "    expert_actions=expert_actions,\n",
        "    expert_observations=expert_observations,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Pontuação: [1359.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMVcZyxJVwyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf06837-59b2-4ed0-a41f-c82a466edb4e"
      },
      "source": [
        "# Liberando memória das variáveis que não serao mais utilizadas\n",
        "import gc\n",
        "\n",
        "del expert_actions\n",
        "del expert_observations\n",
        "gc.collect()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2304"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOLqZD7ggqkv"
      },
      "source": [
        "try:\n",
        "    expert_observations, expert_actions\n",
        "except NameError:\n",
        "    pass\n",
        "else:\n",
        "  del expert_observations, expert_actions\n",
        "\n",
        "\n",
        "# Carrega os dados salvos\n",
        "data = np.load(\"minicurso_rl/expert_data.npz\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMFddIRoLuCd"
      },
      "source": [
        "## (Sempre) Criando Nossos Datasets\n",
        "\n",
        "- Para usar perfeitamente o PyTorch no processo de treinamento, criamos uma subclasse de `ExpertDataset` do `Dataset` base do Pytorch\n",
        "- Observe que inicializamos o conjunto de dados com as observações e ações de especialistas geradas anteriormente.\n",
        "- Implementamos ainda as [funções mágicas](https://rszalski.github.io/magicmethods/) `__getitem__` e` __len__` do Python para permitir que o manuseio do conjunto de dados do PyTorch acesse linhas arbitrárias no conjunto de dados e informá-lo sobre o comprimento do conjunto de dados.\n",
        "- Para obter mais informações sobre os conjuntos de dados de PyTorch, você pode ler: https://pytorch.org/docs/stable/data.html."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N33dTfs8MADf"
      },
      "source": [
        "from torch.utils.data.dataset import Dataset, random_split"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLuZoKujMFKB"
      },
      "source": [
        "class ExpertDataSet(Dataset):\n",
        "    def __init__(self, expert_observations, expert_actions):\n",
        "        self.observations = expert_observations\n",
        "        self.actions = expert_actions\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return (self.observations[index], self.actions[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k5Id9xDo0Bu"
      },
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pandas as pd\n",
        "\n",
        "class PyArrowDataSet(Dataset):\n",
        "    def __init__(self, expert_observations, expert_actions, batch_size=128, filename=\"dataset.parquet\"):\n",
        "        # self.observations = expert_observations.copy()\n",
        "        # self.actions = expert_actions.copy()\n",
        "        self.batch_size = batch_size\n",
        "        self.df = pd.DataFrame({\n",
        "            \"observations\": expert_observations,\n",
        "            \"actions\": expert_actions,\n",
        "        })\n",
        "        table = pa.Table.from_pandas(self.df)\n",
        "        # pq.write_to_dataset(\n",
        "        #     table,\n",
        "        #     root_path='dataset.parquet',\n",
        "        #     partition_cols=['partone', 'parttwo'],\n",
        "        # )\n",
        "        pq.write_table(table, filename)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        _file = pq.parquet.ParquetFile(self.filename)\n",
        "        batches = _file.iter_batches(batch_size) #batches will be a generator\n",
        "\n",
        "        for batch in batches:\n",
        "            process(batch)\n",
        "\n",
        "        return (self.observations[index], self.actions[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FG-WTCL0pH1"
      },
      "source": [
        "# Adapted from https://realpython.com/storing-images-in-python/ (Many thx!)\n",
        "\n",
        "# !pip install h5py > /dev/null 2>&1\n",
        "\n",
        "import h5py\n",
        "from pathlib import Path\n",
        "\n",
        "hdf5_dir = Path(\"data/hdf5/\")\n",
        "hdf5_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def store_batch_hdf5(root, images, labels, batch_index):\n",
        "    \"\"\" Stores an array of images to HDF5.\n",
        "        Parameters:\n",
        "        ---------------\n",
        "        images       images array, (N, 84, 84, 3) to be stored\n",
        "        labels       labels array, (N, 1) to be stored\n",
        "    \"\"\"\n",
        "    # Create a new HDF5 file\n",
        "    (hdf5_dir / root).mkdir(parents=True, exist_ok=True)\n",
        "    file = h5py.File(hdf5_dir / Path(root) / f\"batch_{batch_index}.h5\", \"w\")\n",
        "\n",
        "    # Create a dataset in the file\n",
        "    dataset = file.create_dataset(\n",
        "        \"images\", np.shape(images), h5py.h5t.STD_U8BE, data=images\n",
        "    )\n",
        "    meta_set = file.create_dataset(\n",
        "        \"labels\", np.shape(labels), h5py.h5t.STD_U8BE, data=labels\n",
        "    )\n",
        "    file.close()\n",
        "\n",
        "def read_batch_hdf5(root, batch_index):\n",
        "    \"\"\" Reads image from HDF5.\n",
        "        Parameters:\n",
        "        ---------------\n",
        "        batch_index   index of batch to read\n",
        "\n",
        "        Returns:\n",
        "        ----------\n",
        "        images      images array, (N, 84, 84, 3) to be stored\n",
        "        labels      associated meta data, int label (N, 1)\n",
        "    \"\"\"\n",
        "    images, labels = [], []\n",
        "\n",
        "    # Open the HDF5 file\n",
        "    file = h5py.File(hdf5_dir / Path(root) / f\"batch_{batch_index}.h5\", \"r+\")\n",
        "\n",
        "    images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
        "    labels = np.array(file[\"/labels\"]).astype(\"uint8\")\n",
        "\n",
        "    file.close()\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def generate_batch_indexes(total, batch_size, shuffle=True):\n",
        "    indexes = np.arange(total)\n",
        "    if True:\n",
        "        rng = np.random.default_rng()\n",
        "        rng.shuffle(indexes)\n",
        "\n",
        "\n",
        "    num_batches = indexes.shape[0] // batch_size\n",
        "    if num_batches < 1:\n",
        "        raise ValueError(\"A quantidade de dados precisa ser maior que o tamanho do batch\")\n",
        "    \n",
        "    batches = indexes[:batch_size * num_batches].reshape(-1, batch_size)\n",
        "    for i in range(num_batches):\n",
        "        yield batches[i]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAd376WSzs8A"
      },
      "source": [
        "class HDF5DataSet(Dataset):\n",
        "    def __init__(self, root, batch_size=128):\n",
        "        self.root = root\n",
        "        self.batch_size = batch_size\n",
        "        self.total_batches = 0\n",
        "\n",
        "    def add_data(self, observations: np.ndarray, actions: np.ndarray, shuffle=True):\n",
        "        assert observations.shape[0] == actions.shape[0] and observations.shape[0]\n",
        "\n",
        "        i = 0\n",
        "        for i, batch in enumerate(generate_batch_indexes(len(observations), self.batch_size, shuffle)):\n",
        "            store_batch_hdf5(self.root,\n",
        "                             np.take(observations, batch, axis=0),\n",
        "                             np.take(actions, batch),\n",
        "                             self.total_batches + i)\n",
        "        self.total_batches += i+1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return read_batch_hdf5(self.root, index)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_batches"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGLryFyMMJjF"
      },
      "source": [
        "## Instanciar o Dataset Especialista\n",
        "\n",
        "Agora instanciamos o `ExpertDataSet` e o dividimos em conjuntos de dados de treinamento e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve60YhwzMHfK"
      },
      "source": [
        "expert_dataset = ExpertDataSet(data[\"expert_observations\"], data[\"expert_actions\"])\n",
        "\n",
        "del data\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "train_size = int(0.8 * len(expert_dataset))     # 80% dos dados para treinamento\n",
        "test_size = len(expert_dataset) - train_size    # E o restante dos dados para teste\n",
        "\n",
        "train_expert_dataset, test_expert_dataset = random_split(\n",
        "    expert_dataset, [train_size, test_size]\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMqxQ3YZMaXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dadd2c2-97a4-44c3-f61d-9edf282ee213"
      },
      "source": [
        "print(\"# test_expert_dataset: \", len(test_expert_dataset))\n",
        "print(\"# train_expert_dataset: \", len(train_expert_dataset))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# test_expert_dataset:  6000\n",
            "# train_expert_dataset:  24000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzMyjklbCArD"
      },
      "source": [
        "## Treinar o agente estudante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP5nBNn1MkvP"
      },
      "source": [
        "Nossos próximos passos:\n",
        "\n",
        "1. Extraímos a rede de políticas de nosso aluno.\n",
        "2. Carregamos o conjunto de dados de especialistas (rotulados) contendo observações de especialistas como entradas e ações de especialistas como alvos.\n",
        "3. Realizamos aprendizagem supervisionada, ou seja, ajustamos os parâmetros da rede de políticas de forma que, dadas as observações de especialistas como entradas para a rede, suas saídas correspondam aos alvos (ações de especialistas).\n",
        "\n",
        "\n",
        "Ao treinar a rede de políticas dessa maneira, o agente aluno correspondente é ensinado a se comportar como o agente especialista que foi usado para criar o conjunto de dados especialista (Behavior Cloning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3nF62p95yEN"
      },
      "source": [
        "## (Sempre) Inicializar Variáveis importantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5d_C46gu8Yp"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG0oRMriPWxX"
      },
      "source": [
        "# Hyper Parameters\n",
        "batch_size=32\n",
        "epochs=20\n",
        "scheduler_gamma=0.99\n",
        "learning_rate=5e-3\n",
        "log_interval=100\n",
        "no_cuda=False    \n",
        "seed=1\n",
        "test_batch_size=128"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO1OG1uTPoNL"
      },
      "source": [
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7mj915v_IJm"
      },
      "source": [
        "## Criando a rede estudante\n",
        "\n",
        "Agora iremos definir a rede neural que iremos utilizar para o aluno estudante. Aqui criamos um agente de aprendizado por reforço, e extraimos dele a rede da política. Alternativamente você pode construir a sua própria rede neural.\n",
        "\n",
        "Como estamos utilizando imagens como entrada, iremos utilizar uma rede chamada de Rede Neural Convolucional (Convolutional Neural Network - CNN).\n",
        "\n",
        "<br>\n",
        "\n",
        "- https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-cnn-26a14c2ea29\n",
        "\n",
        "- https://medium.com/swlh/introduction-to-cnn-image-classification-using-cnn-in-pytorch-11eefae6d83c\n",
        "\n",
        "- https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39sT4rgBPslk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56783cc-3f98-4ec1-8080-50180cee62a0"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "student = PPO('CnnPolicy', env, verbose=1)\n",
        "\n",
        "# Extrair politica inicial\n",
        "model = student.policy.to(device)\n",
        "\n",
        "# Mostra um sumário da rede, mostrando todas as suas camadas \n",
        "summary(model, (4, 84, 84))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 20, 20]           8,224\n",
            "              ReLU-2           [-1, 32, 20, 20]               0\n",
            "            Conv2d-3             [-1, 64, 9, 9]          32,832\n",
            "              ReLU-4             [-1, 64, 9, 9]               0\n",
            "            Conv2d-5             [-1, 64, 7, 7]          36,928\n",
            "              ReLU-6             [-1, 64, 7, 7]               0\n",
            "           Flatten-7                 [-1, 3136]               0\n",
            "            Linear-8                  [-1, 512]       1,606,144\n",
            "              ReLU-9                  [-1, 512]               0\n",
            "        NatureCNN-10                  [-1, 512]               0\n",
            "     MlpExtractor-11     [[-1, 512], [-1, 512]]               0\n",
            "           Linear-12                    [-1, 1]             513\n",
            "           Linear-13                    [-1, 9]           4,617\n",
            "================================================================\n",
            "Total params: 1,689,258\n",
            "Trainable params: 1,689,258\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 1.64\n",
            "Params size (MB): 6.44\n",
            "Estimated Total Size (MB): 8.19\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36xmtUnNPyy0"
      },
      "source": [
        "## (Sempre) Inicializar funções de Treino\n",
        "\n",
        "Como visto em aula, queremos minimizar a diferença entre a resposta correta e a resposta do modelo. A primeira tarefa é, portanto, definir um critério que mede o erro entre cada elemento na entrada x e no destino y.\n",
        "\n",
        "Aqui precisamos nos atentar em alguns pontos. \n",
        "\n",
        "Box e Discrete são os dois tipos de espaço mais comumente usados para representar os espaços de Observação e Ação em ambientes do Gym. \n",
        "\n",
        "- Box: Uma caixa dimensional, onde cada coordenada fica entre um limite definido por [baixo, alto]\n",
        "- Discrete: O espaço consiste em n pontos distintos, cada um mapeado para um valor inteiro no intervalo [0, n-1]\n",
        "\n",
        "\n",
        "No caso do ambiente Enduro,as ações são discretas, onde será selecionado um valor entre 0 e n-1 para ser aplicado ao ambiente.\n",
        "\n",
        "As saídas da rede é uma lista de probabilidade de selecionar cada uma dessas ações. Iremos executar a ação com a maior probabilidade dada pela rede.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1KEBtAKI5kOAC7PfcK3SRQIdE1sQwmAza' width=\"550\" height=\"180\">\n",
        "\n",
        "Como iremos definir o erro da entrada e do destino?\n",
        "\n",
        "O que queremos minimizar é a distância entre duas distribuições de probabilidade - prevista e real.\n",
        "\n",
        "Considere um classificador que prediz se um dado animal é um cão, gato ou cavalo com uma probabilidade associada a cada um. \n",
        "\n",
        "Suponha que a imagem original seja de um cachorro e o modelo preveja 0.2, 0.7, 0.1 como probabilidade para três classes em que as probabilidades verdadeiras se parecem com 1, 0, 0. O que desejamos idealmente é que nossas probabilidades previstas sejam próximas às originais. Portanto, precisamos nos certificar de que estamos minimizando a diferença entre as duas probabilidades.\n",
        "\n",
        "Para isso temos uma loss chamada de Cross-Entropy que nos ajuda a calcular essa diferença. Veja mais em: https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5pDD8T3WAF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9609323-1be6-4fcb-eb1e-94c13d606c92"
      },
      "source": [
        "nb_actions = env.action_space.n\n",
        "print(\"O número total de ações possíveis é: \", nb_actions)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número total de ações possíveis é:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzYyTCZTPpgp"
      },
      "source": [
        "# HW: Implementar função de Loss\n",
        "\n",
        "# from typing import List\n",
        "\n",
        "# def get_cross_entropy_loss():\n",
        "#   def cross_entropy_loss(model_out, true_out):\n",
        "#     return -np.sum([true_out[i] * np.log(model_out[i]) for i in range(len(true_out))])\n",
        "#   return cross_entropy_loss\n",
        "\n",
        "# criterion = get_cross_entropy_loss()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQ8IB4dbOH9"
      },
      "source": [
        "# HW: Implementar função de Acurácia\n",
        "def acc(model_out: torch.Tensor, true_out: torch.Tensor):\n",
        "    # return np.sum(model_out.detach().cpu().numpy() == true_out) / len(true_out)\n",
        "    return torch.sum(torch.argmax(model_out, dim=1).eq(true_out))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtAIxZyPQ16h"
      },
      "source": [
        "# HW: Implementar função de Treino\n",
        "# ela deve retornar informações de loss e acurácia\n",
        "\n",
        "def train():\n",
        "    _loss = 0.0\n",
        "    _acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        data = data.permute(0, 3, 1, 2)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        if isinstance(env.action_space, gym.spaces.Box):\n",
        "            # A2C/PPO policy outputs actions, values, log_prob\n",
        "            action, _, _ = model(data)\n",
        "            action_prediction = action.double()\n",
        "        else:\n",
        "            # Retrieve the logits for A2C/PPO when using discrete actions\n",
        "            latent_pi, _, _ = model._get_latent(data)\n",
        "            logits = model.action_net(latent_pi)\n",
        "            action_prediction = logits\n",
        "            target = target.long()\n",
        "\n",
        "        train_loss = criterion(action_prediction, target)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        _loss += train_loss.data.cpu().numpy()\n",
        "        _acc += acc(action_prediction, target).data.cpu().numpy()\n",
        "    _loss /= float(len(train_loader.dataset))\n",
        "    _acc /= float(len(train_loader.dataset))\n",
        "\n",
        "    print(f\"Conjunto de Treino: Loss {_loss:.4f} \\tAccuracy {_acc*100:.2f} %\")\n",
        "    return _loss, _acc"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyZmHN9wRMHW"
      },
      "source": [
        "def test():\n",
        "    _loss = 0.0\n",
        "    _acc = 0.0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.permute(0, 3, 1, 2)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            if isinstance(env.action_space, gym.spaces.Box):\n",
        "                # A2C/PPO policy outputs actions, values, log_prob\n",
        "                action, _, _ = model(data)\n",
        "                action_prediction = action.double()\n",
        "            else:\n",
        "                # Retrieve the logits for A2C/PPO when using discrete actions\n",
        "                latent_pi, _, _ = model._get_latent(data)\n",
        "                logits = model.action_net(latent_pi)\n",
        "                action_prediction = logits\n",
        "                target = target.long()\n",
        "            \n",
        "            test_loss = criterion(action_prediction, target)\n",
        "\n",
        "            _loss += test_loss.data.cpu().numpy()\n",
        "            _acc += acc(action_prediction, target).data.cpu().numpy()\n",
        "\n",
        "    _loss /= float(len(test_loader.dataset))\n",
        "    _acc /= float(len(test_loader.dataset))\n",
        "    print(f\"Conjunto de Teste: Loss {_loss:.4f} \\tAccuracy {_acc*100:.2f} %\")\n",
        "    return _loss, _acc"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT6wY7mZR3t9"
      },
      "source": [
        "## (Demora) Avaliar agente antes do Treino\n",
        "\n",
        "Avalie o agente antes do treinamento (seu comportamento deve ser aleatório)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48urm-5TR2yX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f02e96-3369-4856-b31f-a7522a65f101"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(student, env, n_eval_episodes=eval_episodes)\n",
        "print(f\"Recompensa média = {mean_reward} +/- {std_reward}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa média = 0.0 +/- 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBmAcuSs6YLa"
      },
      "source": [
        "## Treinar agente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fg10lrfRTuF"
      },
      "source": [
        "# Aqui, usamos PyTorch `DataLoader` para carregar o` ExpertDataset` criado anteriormente para treinamento e teste\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_expert_dataset, batch_size=batch_size, shuffle=True, **kwargs\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_expert_dataset, batch_size=test_batch_size, shuffle=True, **kwargs,\n",
        ")\n",
        "\n",
        "# Defina um Otimizador e uma programação de taxa de aprendizagem (learning rate).\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=scheduler_gamma)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve8D386FSZU0"
      },
      "source": [
        "Tendo definido o procedimento de treinamento, podemos agora executar o treinamento!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAiOxXLnSfIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93530aa-f6a3-415a-a4c2-e35de982b64e"
      },
      "source": [
        "# Agora estamos finalmente prontos para treinar o modelo de política.\n",
        "train_loss, train_acc = [], []\n",
        "test_loss, test_acc = [], []\n",
        "_learning_rate = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    _learning_rate.append(scheduler.get_last_lr()[0])\n",
        "    print(\"learning rate: \", scheduler.get_last_lr()[0])\n",
        "\n",
        "    _train_loss, _train_acc = train()\n",
        "    _test_loss, _test_acc = test()\n",
        "\n",
        "    train_loss.append(_train_loss)\n",
        "    train_acc.append(_train_acc)\n",
        "    test_loss.append(_test_loss)\n",
        "    test_acc.append(_test_acc)\n",
        "    \n",
        "    scheduler.step()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning rate:  0.005\n",
            "Conjunto de Treino: Loss 0.0217 \tAccuracy 74.08 %\n",
            "Conjunto de Teste: Loss 0.0045 \tAccuracy 76.83 %\n",
            "learning rate:  0.00495\n",
            "Conjunto de Treino: Loss 0.0182 \tAccuracy 77.52 %\n",
            "Conjunto de Teste: Loss 0.0044 \tAccuracy 78.13 %\n",
            "learning rate:  0.0049005\n",
            "Conjunto de Treino: Loss 0.0163 \tAccuracy 79.96 %\n",
            "Conjunto de Teste: Loss 0.0043 \tAccuracy 78.95 %\n",
            "learning rate:  0.004851495\n",
            "Conjunto de Treino: Loss 0.0149 \tAccuracy 81.56 %\n",
            "Conjunto de Teste: Loss 0.0041 \tAccuracy 81.13 %\n",
            "learning rate:  0.00480298005\n",
            "Conjunto de Treino: Loss 0.0138 \tAccuracy 83.12 %\n",
            "Conjunto de Teste: Loss 0.0039 \tAccuracy 81.35 %\n",
            "learning rate:  0.0047549502495\n",
            "Conjunto de Treino: Loss 0.0129 \tAccuracy 83.71 %\n",
            "Conjunto de Teste: Loss 0.0039 \tAccuracy 81.70 %\n",
            "learning rate:  0.004707400747005\n",
            "Conjunto de Treino: Loss 0.0122 \tAccuracy 85.07 %\n",
            "Conjunto de Teste: Loss 0.0041 \tAccuracy 82.43 %\n",
            "learning rate:  0.00466032673953495\n",
            "Conjunto de Treino: Loss 0.0115 \tAccuracy 85.82 %\n",
            "Conjunto de Teste: Loss 0.0038 \tAccuracy 82.60 %\n",
            "learning rate:  0.0046137234721396\n",
            "Conjunto de Treino: Loss 0.0109 \tAccuracy 86.54 %\n",
            "Conjunto de Teste: Loss 0.0040 \tAccuracy 82.43 %\n",
            "learning rate:  0.004567586237418204\n",
            "Conjunto de Treino: Loss 0.0106 \tAccuracy 87.02 %\n",
            "Conjunto de Teste: Loss 0.0040 \tAccuracy 82.63 %\n",
            "learning rate:  0.004521910375044022\n",
            "Conjunto de Treino: Loss 0.0096 \tAccuracy 87.98 %\n",
            "Conjunto de Teste: Loss 0.0046 \tAccuracy 82.30 %\n",
            "learning rate:  0.004476691271293582\n",
            "Conjunto de Treino: Loss 0.0093 \tAccuracy 88.41 %\n",
            "Conjunto de Teste: Loss 0.0045 \tAccuracy 81.97 %\n",
            "learning rate:  0.004431924358580646\n",
            "Conjunto de Treino: Loss 0.0089 \tAccuracy 89.11 %\n",
            "Conjunto de Teste: Loss 0.0047 \tAccuracy 82.58 %\n",
            "learning rate:  0.00438760511499484\n",
            "Conjunto de Treino: Loss 0.0086 \tAccuracy 89.59 %\n",
            "Conjunto de Teste: Loss 0.0047 \tAccuracy 81.80 %\n",
            "learning rate:  0.004343729063844891\n",
            "Conjunto de Treino: Loss 0.0080 \tAccuracy 90.13 %\n",
            "Conjunto de Teste: Loss 0.0049 \tAccuracy 82.73 %\n",
            "learning rate:  0.004300291773206443\n",
            "Conjunto de Treino: Loss 0.0083 \tAccuracy 90.30 %\n",
            "Conjunto de Teste: Loss 0.0057 \tAccuracy 81.60 %\n",
            "learning rate:  0.0042572888554743785\n",
            "Conjunto de Treino: Loss 0.0073 \tAccuracy 91.12 %\n",
            "Conjunto de Teste: Loss 0.0057 \tAccuracy 81.93 %\n",
            "learning rate:  0.004214715966919635\n",
            "Conjunto de Treino: Loss 0.0071 \tAccuracy 91.48 %\n",
            "Conjunto de Teste: Loss 0.0056 \tAccuracy 82.15 %\n",
            "learning rate:  0.004172568807250438\n",
            "Conjunto de Treino: Loss 0.0071 \tAccuracy 91.65 %\n",
            "Conjunto de Teste: Loss 0.0062 \tAccuracy 82.75 %\n",
            "learning rate:  0.0041308431191779335\n",
            "Conjunto de Treino: Loss 0.0072 \tAccuracy 91.68 %\n",
            "Conjunto de Teste: Loss 0.0061 \tAccuracy 82.82 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHKjGHz6eMU"
      },
      "source": [
        "## Visualizar Gráficos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOgkr-fPfwxH"
      },
      "source": [
        "import plotly.graph_objs as go"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqF2CXC3efs9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "b2993daa-9df8-4797-c9b6-4f19c378391a"
      },
      "source": [
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        y=train_acc,\n",
        "        x=[ep for ep in range(1, epochs + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Acurácia de Treino\"\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        y=test_acc,\n",
        "        x=[ep for ep in range(1, epochs + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Acurácia de Teste\"\n",
        "    ),\n",
        "])\n",
        "fig.update_layout(\n",
        "    title=\"Acurácia\",\n",
        "    yaxis = dict(\n",
        "        tickformat = \"%\",\n",
        "    ),\n",
        "    xaxis = dict(\n",
        "        title = \"Época\",\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"065c8447-38fc-4793-b5b7-45e5972fe49d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"065c8447-38fc-4793-b5b7-45e5972fe49d\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '065c8447-38fc-4793-b5b7-45e5972fe49d',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"Acur\\u00e1cia de Treino\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [0.7408333333333333, 0.7752083333333334, 0.7995833333333333, 0.8155833333333333, 0.8311666666666667, 0.837125, 0.8507083333333333, 0.8581666666666666, 0.8654166666666666, 0.8701666666666666, 0.87975, 0.884125, 0.891125, 0.895875, 0.9012916666666667, 0.9029583333333333, 0.91125, 0.9147916666666667, 0.9165416666666667, 0.9168333333333333]}, {\"mode\": \"lines\", \"name\": \"Acur\\u00e1cia de Teste\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [0.7683333333333333, 0.7813333333333333, 0.7895, 0.8113333333333334, 0.8135, 0.817, 0.8243333333333334, 0.826, 0.8243333333333334, 0.8263333333333334, 0.823, 0.8196666666666667, 0.8258333333333333, 0.818, 0.8273333333333334, 0.816, 0.8193333333333334, 0.8215, 0.8275, 0.8281666666666667]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Acur\\u00e1cia\"}, \"xaxis\": {\"title\": {\"text\": \"\\u00c9poca\"}}, \"yaxis\": {\"tickformat\": \"%\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('065c8447-38fc-4793-b5b7-45e5972fe49d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVjBiRiZfu2A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "9ca27c61-e687-4273-8b89-af0295bc36ca"
      },
      "source": [
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        y=train_loss,\n",
        "        x=[ep for ep in range(1, epochs + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Loss de Treinamento\"\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        y=test_loss,\n",
        "        x=[ep for ep in range(1, epochs + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Loss de Teste\"\n",
        "    ),\n",
        "])\n",
        "fig.update_layout(\n",
        "    title=\"Loss\",\n",
        "    xaxis = dict(title=\"Época\")\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"c85922fa-6076-44ac-bdf3-315a2986f4ed\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"c85922fa-6076-44ac-bdf3-315a2986f4ed\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'c85922fa-6076-44ac-bdf3-315a2986f4ed',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"Loss de Treinamento\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [0.021659859354918203, 0.01824918497229616, 0.01625185408939918, 0.014876949850780268, 0.013770354025686781, 0.01294948947429657, 0.012177803564195832, 0.011460095396110167, 0.010882417695907256, 0.010603981202933937, 0.009593200154136866, 0.0093356780076089, 0.008918486281298101, 0.008635204071955135, 0.008020205355850825, 0.008343188485441109, 0.007266349628024424, 0.007117973384874252, 0.007122173272713553, 0.00716474943539409]}, {\"mode\": \"lines\", \"name\": \"Loss de Teste\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [0.0045263593047857285, 0.0044084719171126685, 0.004337339445948601, 0.004081550866365433, 0.00386027418076992, 0.0039398072411616645, 0.004098302414019902, 0.0037846869230270387, 0.004026832198103269, 0.003989632432659467, 0.004607921719551086, 0.004496289437015851, 0.0046761386543512345, 0.00473731654882431, 0.004896900027990341, 0.005716575818757216, 0.005703605925043424, 0.005586218774318695, 0.006162810747822126, 0.006140335549910864]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Loss\"}, \"xaxis\": {\"title\": {\"text\": \"\\u00c9poca\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c85922fa-6076-44ac-bdf3-315a2986f4ed');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_bpFhUeSZvy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "3c3b295a-1ed3-4c47-aeb0-55495bc3d8a1"
      },
      "source": [
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        y=_learning_rate,\n",
        "        x=[ep for ep in range(1, epochs + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Learning Rate\"\n",
        "    ),\n",
        "])\n",
        "fig.update_layout(\n",
        "    title=\"Learning Rate\",\n",
        "    xaxis = dict(title=\"Época\")\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"88a9a21b-621a-4dce-b4f8-4fcbc8b36964\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"88a9a21b-621a-4dce-b4f8-4fcbc8b36964\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '88a9a21b-621a-4dce-b4f8-4fcbc8b36964',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"Learning Rate\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [0.005, 0.00495, 0.0049005, 0.004851495, 0.00480298005, 0.0047549502495, 0.004707400747005, 0.00466032673953495, 0.0046137234721396, 0.004567586237418204, 0.004521910375044022, 0.004476691271293582, 0.004431924358580646, 0.00438760511499484, 0.004343729063844891, 0.004300291773206443, 0.0042572888554743785, 0.004214715966919635, 0.004172568807250438, 0.0041308431191779335]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Learning Rate\"}, \"xaxis\": {\"title\": {\"text\": \"\\u00c9poca\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('88a9a21b-621a-4dce-b4f8-4fcbc8b36964');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivn_FUPTSTA4"
      },
      "source": [
        "Finalmente, vamos testar o quão bem nosso aluno aprendeu a imitar o comportamento do especialista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuCpdvyxeG5A"
      },
      "source": [
        "# Inserir a rede treinada de volta no agente estudante\n",
        "student.policy = model"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo_D5XuPMjMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5a23db-220b-4806-8add-969ce09f7619"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(student, env, n_eval_episodes=eval_episodes)\n",
        "\n",
        "print(f\"Recompensa média = {mean_reward} +/- {std_reward}\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa média = 10.8 +/- 14.600000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBTDrSJg6m7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cfc359-bccf-40cf-d3d7-753d53012ee7"
      },
      "source": [
        "frames = []\n",
        "episodes = 1\n",
        "for episode in range(1, episodes+1):\n",
        "    obs = env.reset()     \n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        frames.append(env.render(mode='rgb_array'))           \n",
        "        action = student.predict(obs, deterministic=True)\n",
        "        n_obs, reward, done, info = env.step(action)       \n",
        "        score += reward\n",
        "        obs = n_obs.copy()\n",
        "    print(\"\\n\\nEpisódio: {} Pontuação: {}\".format(episode,score))\n",
        "env.close()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Episódio: 1 Pontuação: [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ip8jLMAK5_3"
      },
      "source": [
        "display.HTML(display_anim(frames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivURRR0sbxgr"
      },
      "source": [
        "# Bônus\n",
        "\n",
        "O algoritimo Dagger é um algoritimo interativo que aproxima as distribuições de trajetórias de alunos e especialistas ao rotular pontos de dados adicionais resultantes da aplicação da política atual.\n",
        "\n",
        "Em sua forma mais simples, o algoritmo procede da seguinte maneira. Na primeira iteração, ele usa a política do especialista para reunir um conjunto de dados de trajetórias $D$ e treinar uma política $\\pi_{2}$ que melhor imita o especialista nessas trajetórias. Então, na iteração $n$, ele usa $\\pi_{n}$ para coletar mais trajetórias e adiciona essas trajetórias ao conjunto de dados $D$. A próxima política $\\pi_{n+1}$ é a que melhor imita o especialista em todo o conjunto de dados $D$.\n",
        "\n",
        "É como se a cada passo, perguntássemos ao especialista sua opinião sobre nossa trajetória atual. Em seguida, reunindo esta opinião (sua resposta aos estados que encontramos) e os conjuntos de dados anteriores de trajetórias,\n",
        "podemos treinar uma nova política mais precisa porque estamos levando em consideração a opinião de mais especialistas.\n",
        "\n",
        "<br>\n",
        "\n",
        "Algoritmo [Dagger](http://proceedings.mlr.press/v15/ross11a/ross11a.pdf):\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1rMERL80AGmDRR0fKVfq0KjhJjGPt4YKt' width=\"450\" height=\"250\">\n",
        "\n",
        "\n",
        "A tarefa bônus consistirá em implementar o algoritmo Dagger.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgSLnp1aDV0X"
      },
      "source": [
        "## (Sempre e antes de reiniciar treinos) Defining basic functions and reinitializing (Hyper)parameters and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj5h2g2ZJl8W"
      },
      "source": [
        "episodes_per_train = 2\n",
        "batch_size = 128\n",
        "batch_size_test = 128\n",
        "num_interactions = int(2.5e3)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Pw6-lIdHuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a445be0a-06c7-4944-a6a5-3a15070e66c1"
      },
      "source": [
        "dagger_student = PPO('CnnPolicy', env, verbose=1)\n",
        "dagger_model = dagger_student.policy.to(device)\n",
        "expert_model = expert.policy.to(device)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyVgDD7EnfYg"
      },
      "source": [
        "def prepare_obs(obs):\n",
        "  return torch.from_numpy(obs).permute(0, 3, 1, 2).to(device)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lCX781hW_lp"
      },
      "source": [
        "def get_merged_action(expert_model, dagger_model, beta, obs):\n",
        "    if np.random.random_sample() < beta:\n",
        "        return expert_model.predict(obs, deterministic=True)\n",
        "    return dagger_model.predict(obs, deterministic=True)\n",
        "    #     return expert_model(prepare_obs(obs), deterministic=True)\n",
        "    # return dagger_model(prepare_obs(obs), deterministic=True)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-TxAivYWazP"
      },
      "source": [
        "# This is equivalent to run the game one time\n",
        "def get_merged_trajectory(expert_model, dagger_model, size, env, beta):\n",
        "    trajectory = np.empty((num_interactions, ) + env.observation_space.shape)\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    count = 0\n",
        "    while not done and count < size:\n",
        "        trajectory[count] = obs.copy()\n",
        "        action, _ = get_merged_action(expert_model, dagger_model, beta, obs)\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "        obs = next_obs.copy()\n",
        "        count += 1\n",
        "    return trajectory\n",
        "\n",
        "def generate_merged_trajectory(expert_model, dagger_model, size, env, beta, batch_size):\n",
        "    trajectory = np.empty((batch_size, ) + env.observation_space.shape)\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    count = 0\n",
        "    while not done and count < size:\n",
        "        trajectory[count] = obs.copy()\n",
        "        action, _ = get_merged_action(expert_model, dagger_model, beta, obs)\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "        obs = next_obs.copy()\n",
        "        count += 1\n",
        "        count %= batch_size\n",
        "        if count == batch_size-1:\n",
        "            yield trajectory.copy()"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmMYlcSsWEu6"
      },
      "source": [
        "def get_random_trajectory(model, env, size=num_interactions, sample=0.2):\n",
        "    rng = np.random.default_rng()\n",
        "    trajectory = np.empty((size,) + env.observation_space.shape)\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    count = 0\n",
        "    while not done and count < size:\n",
        "        trajectory[count] = obs.copy()\n",
        "        action, _ = model.predict(obs, deterministic = True)\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "        obs = next_obs.copy()\n",
        "        count += 1\n",
        "    return rng.choice(trajectory, size=int(size*sample), axis=0).copy()\n",
        "\n",
        "def generate_random_trajectory(model, env, size=num_interactions, batch_size=128):\n",
        "    rng = np.random.default_rng()\n",
        "    trajectory = np.empty((batch_size,) + env.observation_space.shape)\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    count = 0\n",
        "    while not done and count < size:\n",
        "        trajectory[count] = obs.copy()\n",
        "        action, _ = model.predict(obs, deterministic = True)\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "        obs = next_obs.copy()\n",
        "        count += 1\n",
        "        count %= batch_size\n",
        "        if count == batch_size-1:\n",
        "            yield rng.choice(trajectory, size=batch_size, axis=0)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KY5hIkPnyAn"
      },
      "source": [
        "# def get_actions(model, trajectories):\n",
        "#   actions = []\n",
        "#   for t in trajectories:\n",
        "#     a, _, _ = model(prepare_obs(t), deterministic=True)\n",
        "#     actions.append(a)\n",
        "#   return actions\n",
        "\n",
        "def get_actions(model, trajectory):\n",
        "    a, _ = model.predict(trajectory, deterministic=True)\n",
        "    return a"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl9SKTeSXDzp"
      },
      "source": [
        "class SchedulerBeta:\n",
        "  def __init__(self, initial_beta = 1.0, decay_rate = 0.9):\n",
        "      self.initial_beta = initial_beta\n",
        "      self.decay_rate = decay_rate\n",
        "      self.reset()\n",
        "\n",
        "  def get_beta(self):\n",
        "    return self.beta\n",
        "\n",
        "  def reset(self):\n",
        "      self.beta = self.initial_beta\n",
        "      self.i = 0\n",
        "      return self.beta\n",
        "\n",
        "  def step(self):\n",
        "      self.beta *= self.decay_rate\n",
        "      self.i += 1\n",
        "      return self.beta"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM0ZZkmLFiRO"
      },
      "source": [
        "train_loss, train_acc = [], []\n",
        "test_loss, test_acc = [], []\n",
        "_learning_rate = []\n",
        "\n",
        "optimizer = optim.Adam(dagger_model.parameters(), lr=learning_rate)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=scheduler_gamma)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr0fsCXX5vyf"
      },
      "source": [
        "import os\n",
        "min_val_loss = np.inf\n",
        "MODEL_PATH = \"model/\"\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "  %mkdir $MODEL_PATH\n",
        "DAGGER_MODEL_NAME = \"dagger.model\"\n",
        "\n",
        "def check_save(model, val_loss, name=DAGGER_MODEL_NAME):\n",
        "    global min_val_loss\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss.copy()\n",
        "        path = MODEL_PATH + name\n",
        "        model.save(path)\n",
        "        print(f\"Salvando melhor modelo: {name}\\tValidation loss: {val_loss}\")"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCe68OZIIZk-"
      },
      "source": [
        "def run_episode(pi, loader, train=True):\n",
        "    _loss = 0.0\n",
        "    _acc = 0.0\n",
        "    name = 'treino' if train else 'teste'\n",
        "\n",
        "    for data, target in loader:\n",
        "        # Adaptation needed to run model with HDF5 Loadings\n",
        "        # To reajust shapes to correct values\n",
        "        # data = data.reshape(-1, 84, 84, 4)\n",
        "        data = data.reshape((-1,) + env.observation_space.shape)\n",
        "        target = target.flatten()\n",
        "\n",
        "        data = data.permute(0, 3, 1, 2)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        if isinstance(env.action_space, gym.spaces.Box):\n",
        "            # A2C/PPO policy outputs actions, values, log_prob\n",
        "            action, _, _ = pi(data)\n",
        "            action_prediction = action.double()\n",
        "        else:\n",
        "            # Retrieve the logits for A2C/PPO when using discrete actions\n",
        "            latent_pi, _, _ = pi._get_latent(data)\n",
        "            logits = pi.action_net(latent_pi)\n",
        "            action_prediction = logits\n",
        "            target = target.long()\n",
        "\n",
        "        loss = criterion(action_prediction, target)\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        _loss += loss.data.cpu().numpy()\n",
        "        _acc += acc(action_prediction, target).data.cpu().numpy()\n",
        "    _loss /= float(len(loader.dataset) * batch_size)\n",
        "    _acc /= float(len(loader.dataset) * batch_size)\n",
        "\n",
        "    print(f\"Resultado do {name}: Loss {_loss:.4f} \\tAccuracy {_acc*100:.2f} %\")\n",
        "\n",
        "    if not train:\n",
        "        check_save(pi, _loss)\n",
        "        \n",
        "    return _loss, _acc"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SC9Ik332YrM"
      },
      "source": [
        "def train_dagger(dagger_model, train_loader, test_loader):\n",
        "    for episode in range(1, episodes_per_train + 1):\n",
        "        _learning_rate.append(scheduler.get_last_lr()[0])\n",
        "        print(\"learning rate: \", scheduler.get_last_lr()[0])\n",
        "\n",
        "        _train_loss, _train_acc = run_episode(dagger_model, train_loader, train=True)\n",
        "        with torch.no_grad():\n",
        "          _test_loss, _test_acc = run_episode(dagger_model, test_loader, train=False)\n",
        "\n",
        "        train_loss.append(_train_loss)\n",
        "        train_acc.append(_train_acc)\n",
        "        test_loss.append(_test_loss)\n",
        "        test_acc.append(_test_acc)\n",
        "        \n",
        "        scheduler.step()"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzFdRgl2Dco-"
      },
      "source": [
        "## Basic Dagger implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms4i6RF6Zr3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4723c817-8c1f-4fd7-8853-c2954e236f27"
      },
      "source": [
        "N = 8\n",
        "num_interactions = int(2.5e3)\n",
        "\n",
        "beta_scheduler = SchedulerBeta()\n",
        "\n",
        "trajectory, actions = None, None\n",
        "\n",
        "test_trajectory = get_random_trajectory(expert_model, env, size=num_interactions, sample=0.2)\n",
        "test_actions = get_actions(expert_model, test_trajectory)\n",
        "test_dataset = ExpertDataSet(test_trajectory, test_actions)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset, batch_size=batch_size_test, shuffle=True\n",
        ")\n",
        "del test_trajectory, test_actions, test_dataset\n",
        "\n",
        "# Running the algorithm\n",
        "D_obs = np.array([]).reshape((0, ) + env.observation_space.shape)\n",
        "D_actions = np.array([])\n",
        "for i in range(1, N+1):\n",
        "    print(f\"Episode: {i}\")\n",
        "    print(f\"beta: {beta_scheduler.get_beta()}\")\n",
        "    trajectory = get_merged_trajectory(expert_model,\n",
        "                                       dagger_model,\n",
        "                                       num_interactions,\n",
        "                                       env,\n",
        "                                       beta_scheduler.get_beta())\n",
        "    actions = get_actions(expert_model, trajectory)\n",
        "    D_obs = np.vstack([D_obs, trajectory])\n",
        "    D_actions = np.append(D_actions, actions)\n",
        "\n",
        "    train_dataset = ExpertDataSet(D_obs, D_actions)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs\n",
        "    )\n",
        "    del train_dataset, actions\n",
        "\n",
        "    train_dagger(dagger_model, train_loader, test_loader)\n",
        "    beta_scheduler.step()\n",
        "    print(\"\\n\")\n",
        "del D_obs, D_actions\n",
        "env.close()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1\n",
            "beta: 1.0\n",
            "learning rate:  0.0042572888554743785\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.69 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.31 %\n",
            "learning rate:  0.004214715966919635\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.69 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.29 %\n",
            "\n",
            "\n",
            "Episode: 2\n",
            "beta: 0.9\n",
            "learning rate:  0.004172568807250438\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.63 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.34 %\n",
            "learning rate:  0.0041308431191779335\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.65 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.36 %\n",
            "\n",
            "\n",
            "Episode: 3\n",
            "beta: 0.81\n",
            "learning rate:  0.004089534687986154\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.59 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.30 %\n",
            "learning rate:  0.004048639341106292\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.63 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.32 %\n",
            "\n",
            "\n",
            "Episode: 4\n",
            "beta: 0.7290000000000001\n",
            "learning rate:  0.00400815294769523\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.58 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.31 %\n",
            "learning rate:  0.003968071418218277\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.63 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.32 %\n",
            "\n",
            "\n",
            "Episode: 5\n",
            "beta: 0.6561000000000001\n",
            "learning rate:  0.0039283907040360945\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.60 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.28 %\n",
            "learning rate:  0.0038891067969957335\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.64 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.31 %\n",
            "\n",
            "\n",
            "Episode: 6\n",
            "beta: 0.5904900000000002\n",
            "learning rate:  0.003850215729025776\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.67 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.33 %\n",
            "learning rate:  0.0038117135717355183\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.69 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.23 %\n",
            "\n",
            "\n",
            "Episode: 7\n",
            "beta: 0.5314410000000002\n",
            "learning rate:  0.003773596436018163\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.68 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.31 %\n",
            "learning rate:  0.0037358604716579815\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.71 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.22 %\n",
            "\n",
            "\n",
            "Episode: 8\n",
            "beta: 0.47829690000000014\n",
            "learning rate:  0.003698501866941402\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.68 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.25 %\n",
            "learning rate:  0.003661516848271988\n",
            "Resultado do treino: Loss 0.0000 \tAccuracy 0.71 %\n",
            "Resultado do teste: Loss 0.0002 \tAccuracy 0.24 %\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcspmJAw8Rt5"
      },
      "source": [
        "## Dagger with K-fold Cross Validation (not implemented yet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE6NiNCvPjOR"
      },
      "source": [
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# N = 8\n",
        "# num_interactions = int(2.5e3)\n",
        "# beta_scheduler = SchedulerBeta()\n",
        "\n",
        "# trajectory, actions = None, None\n",
        "\n",
        "# # test_trajectory = get_random_trajectory(expert_model, env, size=num_interactions, sample=0.2)\n",
        "# # test_actions = get_actions(expert_model, test_trajectory)\n",
        "# # test_dataset = ExpertDataSet(test_trajectory, test_actions)\n",
        "# # test_loader = torch.utils.data.DataLoader(\n",
        "# #     dataset=test_dataset, batch_size=batch_size_test, shuffle=True\n",
        "# # )\n",
        "# # del test_trajectory, test_actions, test_dataset\n",
        "\n",
        "# # Running the algorithm\n",
        "# D_obs = np.array([]).reshape((0, ) + env.observation_space.shape)\n",
        "# D_actions = np.array([])\n",
        "# for i in range(1, N+1):\n",
        "#     print(f\"Episode: {i}\")\n",
        "#     print(f\"beta: {beta_scheduler.get_beta()}\")\n",
        "#     trajectory = get_merged_trajectory(expert_model,\n",
        "#                                        dagger_model,\n",
        "#                                        num_interactions,\n",
        "#                                        env,\n",
        "#                                        beta_scheduler.get_beta())\n",
        "#     actions = get_actions(expert_model, trajectory)\n",
        "#     D_obs = np.vstack([D_obs, trajectory])\n",
        "#     D_actions = np.append(D_actions, actions.cpu().numpy())\n",
        "\n",
        "#     train_dataset = ExpertDataSet(D_obs, D_actions)\n",
        "#     train_loader = torch.utils.data.DataLoader(\n",
        "#         dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs\n",
        "#     )\n",
        "#     del train_dataset, actions\n",
        "\n",
        "#     train_dagger(dagger_model, train_loader, test_loader)\n",
        "#     beta_scheduler.step()\n",
        "#     print(\"\\n\")\n",
        "# del D_obs, D_actions\n",
        "# env.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGOBRP3j8W0f"
      },
      "source": [
        "## Dagger with large Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axY0SQerECTl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "af1be5e9-2ad6-44a7-c943-4cb01d3c56e8"
      },
      "source": [
        "N = 8\n",
        "num_interactions = int(1e6)\n",
        "\n",
        "episodes_per_train = 2\n",
        "\n",
        "beta_scheduler = SchedulerBeta()\n",
        "\n",
        "train_dataset = HDF5DataSet('train', batch_size)\n",
        "test_dataset = HDF5DataSet('test', batch_size_test)\n",
        "\n",
        "for test_trajectory in generate_random_trajectory(expert_model,\n",
        "                                                  env,\n",
        "                                                  size=num_interactions,\n",
        "                                                  batch_size=batch_size_test):\n",
        "    test_actions = get_actions(expert_model, test_trajectory)\n",
        "    test_dataset.add_data(test_trajectory, test_actions, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset, batch_size=1, shuffle=False\n",
        ")\n",
        "\n",
        "# Running the algorithm\n",
        "D_obs = np.array([]).reshape((0, ) + env.observation_space.shape)\n",
        "D_actions = np.array([])\n",
        "for i in range(1, N+1):\n",
        "    print(f\"Episode: {i}\")\n",
        "    print(f\"beta: {beta_scheduler.get_beta()}\")\n",
        "\n",
        "    for trajectory in generate_merged_trajectory(expert_model,\n",
        "                                                 dagger_model,\n",
        "                                                 num_interactions,\n",
        "                                                 env,\n",
        "                                                 beta_scheduler.get_beta(),\n",
        "                                                 batch_size):\n",
        "        actions = get_actions(expert_model, trajectory)\n",
        "        train_dataset.add_data(trajectory, actions, shuffle=True)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, batch_size=1, shuffle=True, **kwargs\n",
        "    )\n",
        "\n",
        "    train_dagger(dagger_model, train_loader, test_loader)\n",
        "    beta_scheduler.step()\n",
        "    print(\"\\n\")\n",
        "del D_obs, D_actions\n",
        "env.close()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1\n",
            "beta: 1.0\n",
            "learning rate:  0.005\n",
            "Resultado do treino: Loss 0.0191 \tAccuracy 36.98 %\n",
            "Resultado do teste: Loss 0.0127 \tAccuracy 32.03 %\n",
            "Salvando melhor modelo: dagger.model\tValidation loss: 0.012671315044696842\n",
            "learning rate:  0.00495\n",
            "Resultado do treino: Loss 0.0125 \tAccuracy 44.05 %\n",
            "Resultado do teste: Loss 0.0133 \tAccuracy 32.65 %\n",
            "\n",
            "\n",
            "Episode: 2\n",
            "beta: 0.9\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-9bde163c370b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                  \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                                  \u001b[0mbeta_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                                  batch_size):\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-168-930fce6222cc>\u001b[0m in \u001b[0;36mgenerate_merged_trajectory\u001b[0;34m(expert_model, dagger_model, size, env, beta, batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrajectory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_merged_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdagger_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/vec_frame_stack.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m     ) -> Tuple[Union[np.ndarray, Dict[str, np.ndarray]], np.ndarray, np.ndarray, List[Dict[str, Any]],]:\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstackedobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGymStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MqYXBvy8dMg"
      },
      "source": [
        "## Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwi30HQaaZ9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d8fcb7-9cbf-4e1b-9023-46333657acd3"
      },
      "source": [
        "dagger_model.load(MODEL_PATH + DAGGER_MODEL_NAME)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ActorCriticCnnPolicy(\n",
              "  (features_extractor): NatureCNN(\n",
              "    (cnn): Sequential(\n",
              "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (3): ReLU()\n",
              "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "      (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    )\n",
              "    (linear): Sequential(\n",
              "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mlp_extractor): MlpExtractor(\n",
              "    (shared_net): Sequential()\n",
              "    (policy_net): Sequential()\n",
              "    (value_net): Sequential()\n",
              "  )\n",
              "  (action_net): Linear(in_features=512, out_features=9, bias=True)\n",
              "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aeNE6EQ6wDc"
      },
      "source": [
        "## Gerar Gráficos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QngORS_5sVHw"
      },
      "source": [
        "import plotly.graph_objs as go"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDKSwUPWMJmi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e5db381e-9ad2-43f3-96cf-a58c02e30fd1"
      },
      "source": [
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        y=train_acc,\n",
        "        x=[ep for ep in range(1, len(train_acc) + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Acurácia de Treino\"\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        y=test_acc,\n",
        "        x=[ep for ep in range(1, len(test_acc) + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Acurácia de Teste\"\n",
        "    ),\n",
        "])\n",
        "fig.update_layout(\n",
        "    title=\"Acurácia\",\n",
        "    yaxis = dict(\n",
        "        tickformat = \"%\",\n",
        "    ),\n",
        "    xaxis = dict(\n",
        "        title = \"Época\",\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"cc1e019d-6077-41ac-96d0-ffe30393efd4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"cc1e019d-6077-41ac-96d0-ffe30393efd4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'cc1e019d-6077-41ac-96d0-ffe30393efd4',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"Acur\\u00e1cia de Treino\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], \"y\": [0.00171875, 0.0021875, 0.002392578125, 0.003486328125, 0.004446614583333334, 0.004544270833333333, 0.005126953125, 0.00560546875, 0.00566015625, 0.00595703125, 0.005592447916666667, 0.006031901041666667, 0.00529296875, 0.0062109375, 0.00647216796875, 0.00662109375]}, {\"mode\": \"lines\", \"name\": \"Acur\\u00e1cia de Teste\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], \"y\": [0.0017578125, 0.002734375, 0.002734375, 0.0, 0.0, 0.002734375, 0.002734375, 0.002734375, 0.0029296875, 0.00283203125, 0.00107421875, 0.0009765625, 0.00244140625, 0.00185546875, 0.00224609375, 0.001953125]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Acur\\u00e1cia\"}, \"xaxis\": {\"title\": {\"text\": \"\\u00c9poca\"}}, \"yaxis\": {\"tickformat\": \"%\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cc1e019d-6077-41ac-96d0-ffe30393efd4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D232291OMKg_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2ce9cf06-61a2-42af-d8d0-f3e3986d8ba2"
      },
      "source": [
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        y=train_loss,\n",
        "        x=[ep for ep in range(1, len(train_loss) + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Loss de Treinamento\"\n",
        "    ),\n",
        "    go.Scatter(\n",
        "        y=test_loss,\n",
        "        x=[ep for ep in range(1, len(test_loss) + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Loss de Teste\"\n",
        "    ),\n",
        "])\n",
        "fig.update_layout(\n",
        "    title=\"Loss\",\n",
        "    xaxis = dict(title=\"Época\")\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"649d1a15-85e5-4254-964a-254b47d89e37\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"649d1a15-85e5-4254-964a-254b47d89e37\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '649d1a15-85e5-4254-964a-254b47d89e37',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"Loss de Treinamento\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], \"y\": [0.0001576462388038635, 0.00014517594361677767, 0.00011358032235875726, 9.33566887397319e-05, 7.64539442025125e-05, 6.18191040121019e-05, 6.044053152436391e-05, 4.650457529351115e-05, 4.4991071568802e-05, 3.7074377294629815e-05, 4.063792546124508e-05, 3.499169086959834e-05, 6.70528387750632e-05, 3.1221168631288625e-05, 2.6764943831949496e-05, 2.3193463384814094e-05]}, {\"mode\": \"lines\", \"name\": \"Loss de Teste\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], \"y\": [0.00027819303795695305, 0.0005122402682900429, 0.0002630603266879916, 0.00040447991341352463, 0.00046408334746956826, 0.0003474996890872717, 0.0005570321809500456, 0.0005574117880314588, 0.0007266032509505749, 0.00084584541618824, 0.0004064611159265041, 0.0008445736952126026, 0.00018405154114589095, 0.00022879941388964653, 0.00017315081786364316, 0.00018265446415171026]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Loss\"}, \"xaxis\": {\"title\": {\"text\": \"\\u00c9poca\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('649d1a15-85e5-4254-964a-254b47d89e37');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7bYpLeMKkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "3d41cdb8-a2b9-48b9-cf01-93d0417fa420"
      },
      "source": [
        "fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        y=_learning_rate,\n",
        "        x=[ep for ep in range(1, epochs + 1)],\n",
        "        mode='lines',\n",
        "        name=\"Learning Rate\"\n",
        "    ),\n",
        "])\n",
        "fig.update_layout(\n",
        "    title=\"Learning Rate\",\n",
        "    xaxis = dict(title=\"Época\")\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"7d151652-16a6-4ef4-891f-0f1a27ca5f68\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"7d151652-16a6-4ef4-891f-0f1a27ca5f68\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '7d151652-16a6-4ef4-891f-0f1a27ca5f68',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"Learning Rate\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"y\": [0.005, 0.00495, 0.0049005, 0.004851495, 0.00480298005, 0.0047549502495, 0.004707400747005, 0.00466032673953495, 0.0046137234721396, 0.004567586237418204, 0.004521910375044022, 0.004476691271293582, 0.004431924358580646, 0.00438760511499484, 0.004343729063844891, 0.004300291773206443]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Learning Rate\"}, \"xaxis\": {\"title\": {\"text\": \"\\u00c9poca\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7d151652-16a6-4ef4-891f-0f1a27ca5f68');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjxHHVWF6zr4"
      },
      "source": [
        "## (Demora) Testar agente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfruOesYfvWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c125a8d0-e87d-40da-988a-af057bef3e89"
      },
      "source": [
        "# Evaluate Dagger\n",
        "mean_reward, std_reward = evaluate_policy(dagger_student, env, n_eval_episodes=eval_episodes)\n",
        "\n",
        "print(f\"Recompensa média = {mean_reward} +/- {std_reward}\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa média = 100.0 +/- 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcf61r-o63sz"
      },
      "source": [
        "## Visualizar Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3sJjggif0_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0b7692-48fe-44b8-cc7e-3f6cfe1764f8"
      },
      "source": [
        "frames = []\n",
        "episodes = 1\n",
        "for episode in range(1, episodes+1):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        frames.append(env.render(mode='rgb_array'))\n",
        "        action = dagger_student.predict(obs, deterministic=True)\n",
        "        n_obs, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "        obs = n_obs.copy()\n",
        "    print(\"\\n\\nEpisódio: {} Pontuação: {}\".format(episode,score))\n",
        "env.close()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Episódio: 1 Pontuação: [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1hPMcT-f502"
      },
      "source": [
        "display.HTML(display_anim(frames))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}